{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the NOMAD documentation for the Schema developed for Computational Materials Scientists , where you can find information about how to use the NOMAD schema definition to store the data output by your simulations. This project contains all the information about the main base sections and their SubSections and Quantities relevant for simulations. We propose here a general schema which could then be used as a basis to build more specific schemas. NOMAD is a free open-source data management platform for Materials Science which follows the F.A.I.R. (Findable, Accessible, Interoperable, and Reusable) principles. This documentation page is a part of the more general NOMAD documentation , as well as on the usage of NOMAD base sections . When designing the sections, we follow SOLID principles for object-oriented programming. And throughout this documentation, we will use UML diagrams , both in a simplified and in a detailed manner, to draw the schemas relationships.","title":"Home"},{"location":"contact/","text":"NOMAD is an open source project that warmly welcomes community projects, contributions, suggestions, bug fixes, and constructive feedback. The contributors to this documentation page are part of the FAIRmat Area C - Theory and Computations team . You can reach us by different channels. You can send as directly an email to the main contributors list: Name E-mail Topics Github profiles Dr. Nathan Daelman nathan.daelman@physik.hu-berlin.de DFT, Precision @ndaelman-hu Dr. Bernadette Mohr mohrbern@physik.hu-berlin.de MD, FF @Bernadette-Mohr Dr. Jos\u00e9 M. Pizarro jose.pizarro@physik.hu-berlin.de GW, DMFT, BSE @JosePizarro3 Dr. Joseph F. Rudzinski ( Coordinator ) joseph.rudzinski@physik.hu-berlin.de General @JFRudzinski Alternatively, you can also: Open an issue in the Github project , and tag any of us. Join the Discord channel and ask us there directly. If you are included as a contributor in the Github project, you can open new discussions regarding a new data schema or modelling you want to see covered.","title":"Contact"},{"location":"general/","text":"Simulation base section \u00b6 In NOMAD, all the simulation metadata is defined in the Simulation section. You can find its Python schema definition in src/nomad_simulations/general.py . This section will appear under the data section for the archive metadata structure of each entry . The Simulation section inherits from a base section BaseSimulation . In NOMAD, a set of base sections derived from the Basic Formal Ontology (BFO) are defined. We used them to define BaseSimulation as an Activity . The UML diagram is: BaseSimulation contains the general information about the Program used, as well as general times of the simulation, e.g., the datetime at which it started ( datetime ) and ended ( datetime_end ). Simulation contains further information about the specific input and output sections ( see below ) The detailed UML diagram of quantities and functions defined for Simulation is thus: Notation for the section attributes in the UML diagram We included the information of each attributes / quantities after its definition. The notation is: <name-of-quantity>: <type-of-quantity>, <units-of-quantity> Thus, cpu1_start: np.float64, s means that there is a quantity named 'cpu1_start' of type numpy.float64 and whose units are 's' (seconds). We also include the existance of sub-sections by bolding the name, i.e.: <name-of-sub-section>: <sub-section-definition> E.g., there is a sub-section under Simulation named 'model_method' whose section defintion can be found in the ModelMethod section. We will represent this sub-section containment in more complex UML diagrams in the future using the containment arrow (see below for an example using Program ). We use double inheritance from EntryData in order to populate the data section in the NOMAD archive. All of the base sections discussed here are subject to the public normalize function in NOMAD. The private function set_system_branch_depth() is related with the ModelSystem base section . Main sub-sections in Simulation \u00b6 The Simulation base section is composed of 4 main sub-sections: Program : contains all the program information, e.g., name of the program, version , etc. ModelSystem : contains all the system information about geometrical positions of atoms, their states, simulation cells, symmetry information, etc. ModelMethod : contains all the methodological information, and it is divided in two main aspects: the mathematical model or approximation used in the simulation (e.g., DFT , GW , ForceFields , etc.) and the numerical settings used to compute the properties (e.g., meshes, self-consistent parameters, basis sets settings, etc.). Outputs : contains all the output properties, as well as references to the ModelSystem used to obtain such properties. It might also contain information which will populate ModelSystem (e.g., atomic occupations, atomic moments, crystal field energies, etc.). Self-consistent steps, SinglePoint entries, and more complex workflows. The minimal unit for storing data in the NOMAD archive is an entry . In the context of simulation data, an entry may contain data from a calculation on an individual system configuration (e.g., a single-point DFT calculation) using only the above-mentioned sections of the Simulation section. Information from self-consistent iterations to converge properties for this configuration are also contained within these sections. More complex calculations that involve multiple configurations require the definition of a workflow section within the archive. Depending on the situation, the information from individual workflow steps may be stored within a single or multiple entries. For example, for efficiency, the data from workflows involving a large amount of configurations, e.g., molecular dynamics trajectories, are stored within a single entry. Other standard workflows store the single-point data in separate entries, e.g., a GW calculation is composed of a DFT SinglePoint entry and a GW SinglePoint entry. Higher-level workflows, which simply connect a series of standard or custom workflows, are typically stored as a separate entry. You can check the NOMAD simulations workflow schema for more information. The following schematic represents a simplified representation of the Simulation section (note that the arrows here are a simple way of visually defining inputs and outputs ): Program \u00b6 The Program base section contains all the information about the program / software / code used to perform the simulation. We consider it to be a (Continuant) Entity and contained within BaseSimulation as a sub-section. The detailed UML diagram is: When writing a parser , we recommend to start by instantiating the Program section and populating its quantities, in order to get acquainted with the NOMAD parsing infrastructure. For example, imagine we have a file which we want to parse with the following information: ! * * * * * * * ! Welcome to SUPERCODE, version 7.0 ... We can parse the program name and version by matching the texts (see, e.g., Wikipedia page for Regular expressions, also called regex ): from nomad.parsing.file_parser import TextParser , Quantity from nomad_simulations import Simulation , Program class SUPERCODEParser : \"\"\" Class responsible to populate the NOMAD `archive` from the files given by a SUPERCODE simulation. \"\"\" def parse ( self , filepath , archive , logger ): output_parser = TextParser ( quantities = [ Quantity ( 'program_version' , r 'version *([\\d\\.]+) *' , repeats = False ) ] ) output_parser . mainfile = filepath simulation = Simulation () simulation . program = Program ( name = 'SUPERCODE' , version = output_parser . get ( 'program_version' ), ) # append `Simulation` as an `archive.data` section archive . data . append ( simulation )","title":"Overview"},{"location":"general/#simulation-base-section","text":"In NOMAD, all the simulation metadata is defined in the Simulation section. You can find its Python schema definition in src/nomad_simulations/general.py . This section will appear under the data section for the archive metadata structure of each entry . The Simulation section inherits from a base section BaseSimulation . In NOMAD, a set of base sections derived from the Basic Formal Ontology (BFO) are defined. We used them to define BaseSimulation as an Activity . The UML diagram is: BaseSimulation contains the general information about the Program used, as well as general times of the simulation, e.g., the datetime at which it started ( datetime ) and ended ( datetime_end ). Simulation contains further information about the specific input and output sections ( see below ) The detailed UML diagram of quantities and functions defined for Simulation is thus: Notation for the section attributes in the UML diagram We included the information of each attributes / quantities after its definition. The notation is: <name-of-quantity>: <type-of-quantity>, <units-of-quantity> Thus, cpu1_start: np.float64, s means that there is a quantity named 'cpu1_start' of type numpy.float64 and whose units are 's' (seconds). We also include the existance of sub-sections by bolding the name, i.e.: <name-of-sub-section>: <sub-section-definition> E.g., there is a sub-section under Simulation named 'model_method' whose section defintion can be found in the ModelMethod section. We will represent this sub-section containment in more complex UML diagrams in the future using the containment arrow (see below for an example using Program ). We use double inheritance from EntryData in order to populate the data section in the NOMAD archive. All of the base sections discussed here are subject to the public normalize function in NOMAD. The private function set_system_branch_depth() is related with the ModelSystem base section .","title":"Simulation base section"},{"location":"general/#sub-sections-in-simulation","text":"The Simulation base section is composed of 4 main sub-sections: Program : contains all the program information, e.g., name of the program, version , etc. ModelSystem : contains all the system information about geometrical positions of atoms, their states, simulation cells, symmetry information, etc. ModelMethod : contains all the methodological information, and it is divided in two main aspects: the mathematical model or approximation used in the simulation (e.g., DFT , GW , ForceFields , etc.) and the numerical settings used to compute the properties (e.g., meshes, self-consistent parameters, basis sets settings, etc.). Outputs : contains all the output properties, as well as references to the ModelSystem used to obtain such properties. It might also contain information which will populate ModelSystem (e.g., atomic occupations, atomic moments, crystal field energies, etc.). Self-consistent steps, SinglePoint entries, and more complex workflows. The minimal unit for storing data in the NOMAD archive is an entry . In the context of simulation data, an entry may contain data from a calculation on an individual system configuration (e.g., a single-point DFT calculation) using only the above-mentioned sections of the Simulation section. Information from self-consistent iterations to converge properties for this configuration are also contained within these sections. More complex calculations that involve multiple configurations require the definition of a workflow section within the archive. Depending on the situation, the information from individual workflow steps may be stored within a single or multiple entries. For example, for efficiency, the data from workflows involving a large amount of configurations, e.g., molecular dynamics trajectories, are stored within a single entry. Other standard workflows store the single-point data in separate entries, e.g., a GW calculation is composed of a DFT SinglePoint entry and a GW SinglePoint entry. Higher-level workflows, which simply connect a series of standard or custom workflows, are typically stored as a separate entry. You can check the NOMAD simulations workflow schema for more information. The following schematic represents a simplified representation of the Simulation section (note that the arrows here are a simple way of visually defining inputs and outputs ):","title":"Main sub-sections in Simulation"},{"location":"general/#program","text":"The Program base section contains all the information about the program / software / code used to perform the simulation. We consider it to be a (Continuant) Entity and contained within BaseSimulation as a sub-section. The detailed UML diagram is: When writing a parser , we recommend to start by instantiating the Program section and populating its quantities, in order to get acquainted with the NOMAD parsing infrastructure. For example, imagine we have a file which we want to parse with the following information: ! * * * * * * * ! Welcome to SUPERCODE, version 7.0 ... We can parse the program name and version by matching the texts (see, e.g., Wikipedia page for Regular expressions, also called regex ): from nomad.parsing.file_parser import TextParser , Quantity from nomad_simulations import Simulation , Program class SUPERCODEParser : \"\"\" Class responsible to populate the NOMAD `archive` from the files given by a SUPERCODE simulation. \"\"\" def parse ( self , filepath , archive , logger ): output_parser = TextParser ( quantities = [ Quantity ( 'program_version' , r 'version *([\\d\\.]+) *' , repeats = False ) ] ) output_parser . mainfile = filepath simulation = Simulation () simulation . program = Program ( name = 'SUPERCODE' , version = output_parser . get ( 'program_version' ), ) # append `Simulation` as an `archive.data` section archive . data . append ( simulation )","title":"Program"},{"location":"howto_use/","text":"How to use the Simulation schema \u00b6 Warning This page is still under construction.","title":"How to use the Simulation schema"},{"location":"howto_use/#how-to-use-the-simulation-schema","text":"Warning This page is still under construction.","title":"How to use the Simulation schema"},{"location":"normalize/","text":"The normalize() function \u00b6 Each base section defined using the NOMAD schema has a set of public functions which can be used at any moment when reading and parsing files in NOMAD. The normalize(archive, logger) function is a special case of such functions, which warrants an in-depth description. This function is run within the NOMAD infrastructure by the MetainfoNormalizer in the following order: A child section's normalize() function is run before their/its parents' normalize() function. For sibling sections, the normalize() function is executed from the smaller to the larger normalizer_level attribute. If normalizer_level is not set or if they are the same for two different sections, the order is established by the attributes definition order in the parent section. Using super().normalize(archive, logger) runs the inherited section normalize function. Let's see some examples. Imagine having the following Section and SubSection structure: from nomad.datamodel.data import ArchiveSection class Section1 ( ArchiveSection ): normalizer_level = 1 def normalize ( self , achive , logger ): # some operations here pass class Section2 ( ArchiveSection ): normalizer_level = 0 def normalize ( self , achive , logger ): super () . normalize ( archive , logger ) # Some operations here or before `super().normalize(archive, logger)` class ParentSection ( ArchiveSection ): sub_section_1 = SubSection ( Section1 . m_def , repeats = False ) sub_section_2 = SubSection ( Section2 . m_def , repeats = True ) def normalize ( self , achive , logger ): super () . normalize ( archive , logger ) # Some operations here or before `super().normalize(archive, logger)` Now, MetainfoNormalizer will be run on the ParentSection . Applying rule 1 , the normalize() functions of the ParentSection 's childs are executed first. The order of these functions is established by rule 2 with the normalizer_level atrribute, i.e., all the Section2 (note that sub_section_2 is a list of sections) normalize() functions are run first, then Section1.normalize() . Then, the order of execution will be: Section2.normalize() Section1.normalize() ParentSection.normalize() In case we do not assign a value to Section1.normalizer_level and Section2.normalizer_level , Section1.normalize() will run first before Section2.normalize() , due to the order of SubSection attributes in ParentSection . Thus the order will be in this case: Section1.normalize() Section2.normalize() ParentSection.normalize() By checking on the normalize() functions and rule 3 , we can establish whether ArchiveSection.normalize() will be run or not. In Section1.normalize() , it will not, while in the other sections, Section2 and ParentSection , it will.","title":"The normalize function"},{"location":"normalize/#the-normalize-function","text":"Each base section defined using the NOMAD schema has a set of public functions which can be used at any moment when reading and parsing files in NOMAD. The normalize(archive, logger) function is a special case of such functions, which warrants an in-depth description. This function is run within the NOMAD infrastructure by the MetainfoNormalizer in the following order: A child section's normalize() function is run before their/its parents' normalize() function. For sibling sections, the normalize() function is executed from the smaller to the larger normalizer_level attribute. If normalizer_level is not set or if they are the same for two different sections, the order is established by the attributes definition order in the parent section. Using super().normalize(archive, logger) runs the inherited section normalize function. Let's see some examples. Imagine having the following Section and SubSection structure: from nomad.datamodel.data import ArchiveSection class Section1 ( ArchiveSection ): normalizer_level = 1 def normalize ( self , achive , logger ): # some operations here pass class Section2 ( ArchiveSection ): normalizer_level = 0 def normalize ( self , achive , logger ): super () . normalize ( archive , logger ) # Some operations here or before `super().normalize(archive, logger)` class ParentSection ( ArchiveSection ): sub_section_1 = SubSection ( Section1 . m_def , repeats = False ) sub_section_2 = SubSection ( Section2 . m_def , repeats = True ) def normalize ( self , achive , logger ): super () . normalize ( archive , logger ) # Some operations here or before `super().normalize(archive, logger)` Now, MetainfoNormalizer will be run on the ParentSection . Applying rule 1 , the normalize() functions of the ParentSection 's childs are executed first. The order of these functions is established by rule 2 with the normalizer_level atrribute, i.e., all the Section2 (note that sub_section_2 is a list of sections) normalize() functions are run first, then Section1.normalize() . Then, the order of execution will be: Section2.normalize() Section1.normalize() ParentSection.normalize() In case we do not assign a value to Section1.normalizer_level and Section2.normalizer_level , Section1.normalize() will run first before Section2.normalize() , due to the order of SubSection attributes in ParentSection . Thus the order will be in this case: Section1.normalize() Section2.normalize() ParentSection.normalize() By checking on the normalize() functions and rule 3 , we can establish whether ArchiveSection.normalize() will be run or not. In Section1.normalize() , it will not, while in the other sections, Section2 and ParentSection , it will.","title":"The normalize() function"},{"location":"model_method/model_method/","text":"ModelMethod \u00b6 Warning This page is still under construction.","title":"ModelMethod"},{"location":"model_method/model_method/#modelmethod","text":"Warning This page is still under construction.","title":"ModelMethod"},{"location":"model_system/model_system/","text":"ModelSystem \u00b6 Warning This page is still under construction.","title":"ModelSystem"},{"location":"model_system/model_system/#modelsystem","text":"Warning This page is still under construction.","title":"ModelSystem"},{"location":"outputs/outputs/","text":"Outputs \u00b6 Warning This page is still under construction.","title":"Outputs"},{"location":"outputs/outputs/#outputs","text":"Warning This page is still under construction.","title":"Outputs"}]}